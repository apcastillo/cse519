# -*- coding: utf-8 -*-
"""DSF_Group_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VS_mKKzp-vS_-LyZ80rxrbbjfAgsfugK

Question:

**Can we predict the number of days a song will stay in the top 200 or viral 50 on spoify?**


get charts data: https://www.kaggle.com/datasets/dhruvildave/spotify-charts

use this data to get artist popularity

use this data to get more info on song from spotify

feature engineering:
  1. count to get # days in each chart: (ANNE)
  2. on each date count the number of country's charts the song apeared in: (ANNE)


TO DO:
create dataset:
pulling https://www.kaggle.com/datasets/dhruvildave/spotify-charts data, then automating the spotify API
"""

# Installing Required Packages
#pip install python-dotenv
#!pip install requests
#!pip install pandas

#import colab_env
import numpy as np
import pandas as pd
import os
import base64
#from dotenv import load_dotenv, find_dotenv
from requests import get, post
import json
import time

#loading
#_ = load_dotenv(find_dotenv()) # reading local .env file

#anne
client_id = 'dca1ba4c350249938ce4544158ae8458' #os.environ['CLIENT_ID']
client_secret = '1c27a8f068f44548bb36c61d6247098e'#os.environ['CLIENT_SECRET']

#privthi
#client_id = 'c392d42a11bf414182f69a9e40526bc6' #os.environ['CLIENT_ID']
#client_secret = 'fde1f03252d749319749f55473ee2247'#os.environ['CLIENT_SECRET']

print(client_id, client_secret)

def get_token():
  auth_string = client_id + ":" + client_secret
  auth_bytes = auth_string.encode("utf-8")
  auth_base64 = str(base64.b64encode(auth_bytes), "utf-8")
  url = "https://accounts.spotify.com/api/token"
  headers = {
      "Authorization": "Basic " + auth_base64,
      "Content-Type": "application/x-www-form-urlencoded"
  }
  data = {"grant_type": "client_credentials"}
  result = post(url, headers=headers, data=data)
  json_result = json.loads (result.content)
  token = json_result["access_token"]
  return token

def get_auth_header (token):
  return {"Authorization": "Bearer " + token}

token = get_token()
# print(token)

def get_artist_id(token, artist_name):
  url = "https://api.spotify.com/v1/search"
  headers = get_auth_header(token)
  query = f"?q={artist_name}&type=artist&limit=1"
  query_url = url + query
  result = get(query_url, headers=headers)
  json_result = json.loads(result.content)
  return json_result['artists']['items'][0]['id']


def get_artist_info(token, artist_id):
  query_url = "https://api.spotify.com/v1/artists/" + artist_id
  headers = get_auth_header(token)
  result = get(query_url, headers=headers)
  if result.status_code != 200:
    print(result.status_code)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
    #print("waiting 31 seconds...")
    #time.sleep(31)
  json_result = json.loads(result.content)
  return json_result

def get_artist_Albums(token, artist_id):
  payload={ 'market':'US', "limit": 50, 'include_groups': ['album']}
  query_url = "https://api.spotify.com/v1/artists/" + artist_id + "/albums"
  headers = get_auth_header(token)
  result = get(query_url, headers=headers, params=payload)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
  json_result = json.loads(result.content)
  return json_result

def get_several_artists(token, artist_ids):
  query_url = "https://api.spotify.com/v1/artists?ids=" + ','.join(artist_ids)
  headers = get_auth_header(token)
  result = get(query_url, headers=headers)
  if result.status_code != 200:
    print(result.status_code)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
    #print("waiting 31 seconds...")
    #time.sleep(31)
  json_result = json.loads(result.content)
  return json_result


def chunker(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))

raw_data = pd.read_csv('charts_USA_unique.csv',
                       parse_dates=['date'])

raw_data.dropna(subset=['title','artist'], inplace = True)
raw_data = raw_data[raw_data['region'] == "United States"]
print(len(raw_data.artist.unique().tolist()))

raw_data['song_num_days_chart_region'] = raw_data.groupby(['chart','region','title','artist'])['date'].transform('nunique')
raw_data['song_num_days_chart_global'] = raw_data.groupby(['chart','title','artist'])['date'].transform('nunique')
raw_data['song_date_num_countries'] = raw_data.groupby(['chart','title','artist','date'])['region'].transform('nunique')
raw_data

"""## Get Artist data and save to file:"""

from pandas.core.frame import DataFrame
artists_columns = [ 'id',
                    #'external_urls',
                    #'href',
                    'followers',
                    'genres',
                    'popularity',
                    #'images',
                    'name',
                    'type',
                    #'uri',
                    'album_names',
                    'release_dates',
                    'total_tracks'
                  ]
if os.path.isfile("artist_data1.csv"):
  df0 = pd.read_csv('artist_data1.csv')
  df0.drop_duplicates(inplace=True)
  df0.to_csv('artist_data1.csv',columns=artists_columns, index=False, header=True, mode='w+')


df1 = DataFrame(columns=[artists_columns])
if os.path.isfile("artist_data1.csv"):
  df1 = pd.read_csv('artist_data1.csv')
  df1 = df1[artists_columns]
  df1.drop_duplicates(inplace=True)
 

test1=raw_data.artist.unique().tolist()
newlist = []
for word in test1:
    word = word.split(",")
    newlist.extend(word)  # <----

test1 = list(map(str.strip, newlist))
test1 = [s.strip('#').upper() for s in test1]
test1 = set(test1)
if len(df1) > 0:
  test2=df1['name'].str.upper().tolist()
else:
  test2=[]
artitst_to_query = set(test1).difference(test2)
artistdata_tosave = dict()
j=0

fifty_IDs = []

file = open('failed_artists.txt','w',encoding="utf-8")
for artist_row in artitst_to_query:
  file.write(artist_row+"\n")

file.close()
'''
for artist_row in artitst_to_query:
  if artist_row in df1.name.unique():
    print("name in: ", artist_row)
    continue
  try:
    artist_id = get_artist_id(token, artist_row)
    if (artist_id in df1.id.unique()):
      print("id1 in: ", artist_row)
      continue
    if ((artist_id in artistdata_tosave)):
      print("id2 in: ", artist_row)
      continue
    fifty_IDs.append(artist_id)
  except:
    print('help!', artist_row)


#simple loop through last 18
sev_arts = get_several_artists(token, fifty_IDs)
#decode and save here
for info in sev_arts['artists']:
  info['followers'] = info['followers']['total']
  del info["uri"]
  del info["images"]
  del info["href"]
  del info['external_urls']
        #call artist album info
  info2 = get_artist_Albums(token, artist_id)
  total_tracks = 0
  album_names = []
  release_dates = []
  for i in info2['items']:
    album_names.append(i['name'])
    release_dates.append(i['release_date'])
    total_tracks += i['total_tracks']
  info['album_names'] = album_names
  info['release_dates'] = release_dates
  info['total_tracks'] = total_tracks
  artistdata_tosave[info['id']] = info


print('save-file')
df2 = pd.DataFrame.from_dict(artistdata_tosave, orient='index', columns=artists_columns)
df2.reset_index(drop=True, inplace=True)
df2.to_csv('artist_data1.csv',columns=artists_columns, index=False, header=False, mode='a')


'''
for artist_row in artitst_to_query:
  repeatartist_row = True
  while repeatartist_row:
    if((len(fifty_IDs)) == 0):
      repeatartist_row = False
      #if artist_row in df1.name.unique():
      # continue
      try:
        artist_id = get_artist_id(token, artist_row)
      except:
        print('failed: ', artist_row)
        continue
      if (artist_id in df1.id) or (artist_id in artistdata_tosave):
        continue
      else:
        fifty_IDs.append(artist_id)
    else:
      repeatartist_row = True
      sev_arts = get_several_artists(token, fifty_IDs)
      fifty_IDs = []
      #decode and save here
      for info in sev_arts['artists']:
        info['followers'] = info['followers']['total']
        del info["uri"]
        del info["images"]
        del info["href"]
        del info['external_urls']
        #call artist album info
        info2 = get_artist_Albums(token, info['id'])
        total_tracks = 0
        album_names = []
        release_dates = []
        for i in info2['items']:
          album_names.append(i['name'])
          release_dates.append(i['release_date'])
          total_tracks += i['total_tracks']
        info['album_names'] = album_names
        info['release_dates'] = release_dates
        info['total_tracks'] = total_tracks
        artistdata_tosave[info['id']] = info
        j=j+1
        #time.sleep(1) #try not to go over limit!!

      if len(artistdata_tosave)>0:
        print('save-file')
        df2 = pd.DataFrame.from_dict(artistdata_tosave, orient='index', columns=artists_columns)
        df2.reset_index(drop=True, inplace=True)
        df2.to_csv('artist_data1.csv',columns=artists_columns, index=False, header=False, mode='a')
        j=0
        artistdata_tosave.clear()

print("fin")


  

