# -*- coding: utf-8 -*-
"""DSF_Group_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VS_mKKzp-vS_-LyZ80rxrbbjfAgsfugK

Question:

**Can we predict the number of days a song will stay in the top 200 or viral 50 on spoify?**


get charts data: https://www.kaggle.com/datasets/dhruvildave/spotify-charts

use this data to get artist popularity

use this data to get more info on song from spotify

feature engineering:
  1. count to get # days in each chart: (ANNE)
  2. on each date count the number of country's charts the song apeared in: (ANNE)


TO DO:
create dataset:
pulling https://www.kaggle.com/datasets/dhruvildave/spotify-charts data, then automating the spotify API
"""

# Installing Required Packages
#pip install python-dotenv
#!pip install requests
#!pip install pandas

#import colab_env
import numpy as np
import pandas as pd
import os
import base64
#from dotenv import load_dotenv, find_dotenv
from requests import get, post
import json
import time

#loading
#_ = load_dotenv(find_dotenv()) # reading local .env file

#anne
client_id = 'dca1ba4c350249938ce4544158ae8458' #os.environ['CLIENT_ID']
client_secret = '1c27a8f068f44548bb36c61d6247098e'#os.environ['CLIENT_SECRET']

#privthi
#client_id = 'c392d42a11bf414182f69a9e40526bc6' #os.environ['CLIENT_ID']
#client_secret = 'fde1f03252d749319749f55473ee2247'#os.environ['CLIENT_SECRET']

print(client_id, client_secret)

def get_token():
  auth_string = client_id + ":" + client_secret
  auth_bytes = auth_string.encode("utf-8")
  auth_base64 = str(base64.b64encode(auth_bytes), "utf-8")
  url = "https://accounts.spotify.com/api/token"
  headers = {
      "Authorization": "Basic " + auth_base64,
      "Content-Type": "application/x-www-form-urlencoded"
  }
  data = {"grant_type": "client_credentials"}
  result = post(url, headers=headers, data=data)
  json_result = json.loads (result.content)
  token = json_result["access_token"]
  return token

def get_auth_header (token):
  return {"Authorization": "Bearer " + token}

token = get_token()
# print(token)

def get_artist_id(token, artist_name):
  url = "https://api.spotify.com/v1/search"
  headers = get_auth_header(token)
  query = f"?q={artist_name}&type=artist&limit=1"
  query_url = url + query
  result = get(query_url, headers=headers)
  json_result = json.loads(result.content)
  return json_result['artists']['items'][0]['id']


def get_artist_info(token, artist_id):
  query_url = "https://api.spotify.com/v1/artists/" + artist_id
  headers = get_auth_header(token)
  result = get(query_url, headers=headers)
  if result.status_code != 200:
    print(result.status_code)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
    #print("waiting 31 seconds...")
    #time.sleep(31)
  json_result = json.loads(result.content)
  return json_result

def get_artist_Albums(token, artist_id):
  payload={ 'market':'US', "limit": 50, 'include_groups': ['album']}
  query_url = "https://api.spotify.com/v1/artists/" + artist_id + "/albums"
  headers = get_auth_header(token)
  result = get(query_url, headers=headers, params=payload)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
  json_result = json.loads(result.content)
  return json_result

def get_several_artists(token, artist_ids):
  query_url = "https://api.spotify.com/v1/artists?ids=" + ','.join(artist_ids)
  headers = get_auth_header(token)
  result = get(query_url, headers=headers)
  if result.status_code != 200:
    print(result.status_code)
  if result.status_code == 429:
    print(result.headers)
    raise ZeroDivisionError
    #print("waiting 31 seconds...")
    #time.sleep(31)
  json_result = json.loads(result.content)
  return json_result


def chunker(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))

raw_data = pd.read_csv('charts.csv',
                       parse_dates=['date'],  nrows=50000)

raw_data.dropna(subset=['title','artist'], inplace = True)

raw_data['song_num_days_chart_region'] = raw_data.groupby(['chart','region','title','artist'])['date'].transform('nunique')
raw_data['song_num_days_chart_global'] = raw_data.groupby(['chart','title','artist'])['date'].transform('nunique')
raw_data['song_date_num_countries'] = raw_data.groupby(['chart','title','artist','date'])['region'].transform('nunique')
raw_data

"""## Get Artist data and save to file:"""

from pandas.core.frame import DataFrame
artists_columns = [ 'id',
                    #'external_urls',
                    #'href',
                    'followers',
                    'genres',
                    'popularity',
                    #'images',
                    'name',
                    'type',
                    #'uri',
                    'album_names',
                    'release_dates',
                    'total_tracks'
                  ]

df1=[]
if os.path.isfile("artist_data.csv"):
  df1 = pd.read_csv ('artist_data.csv')
  df1=df1[artists_columns]

test1=raw_data.artist.unique().tolist()
test2=df1['name'].tolist()
artitst_to_query = set(test1).difference(test2)
artistdata_tosave = dict()
j=0

fifty_IDs = []
for artist_row in artitst_to_query:
  repeatartist_row = True
  artists = artist_row.split(',')
  while repeatartist_row:
    if((len(fifty_IDs) + len(artists)) < 51):
      repeatartist_row = False
      for a in artists:
        a=a.strip()
        a=a.strip('#')
        if a in df1.name.unique():
          continue
        artist_id = get_artist_id(token, a)
        if (artist_id in df1.id.unique()) or (artist_id in artistdata_tosave):
          continue
        else:
          fifty_IDs.append(artist_id)
    else:
      repeatartist_row = True
      sev_arts = get_several_artists(token, fifty_IDs)
      fifty_IDs = []
      #decode and save here
      for info in sev_arts['artists']:
        info['followers'] = info['followers']['total']
        del info["uri"]
        del info["images"]
        del info["href"]
        del info['external_urls']

        artistdata_tosave[info['id']] = info
        j=j+1

      if j > 200:
        print('save-file')
        #df2 = pd.DataFrame.from_dict(artistdata_tosave, orient='index', columns=artists_columns)
        #df2.reset_index(drop=True, inplace=True)
        #df2.to_csv('artist_data.csv',columns=artists_columns, index=False, header=False, mode='a')
        j=0
        artistdata_tosave.clear()

      time.sleep(10)



  

